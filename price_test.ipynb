{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "# LSTMモデルの定義\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTMを通して、最後の隠れ状態を取得\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        # 隠れ状態を全結合層に通す\n",
    "        output = self.fc(hidden[-1])\n",
    "        return output\n",
    "\n",
    "# モデルのパラメータを設定\n",
    "input_size = 1  # 時系列データの特徴量の数（この場合は1）\n",
    "hidden_size = 50  # LSTMの隠れ状態のサイズ\n",
    "output_size = 128  # 出力する潜在変数の次元数\n",
    "\n",
    "# モデルのインスタンス化\n",
    "model = LSTMModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# ダミーの時系列データを生成（長さは15から20のランダム）\n",
    "sequence_length = random.randint(15, 20)\n",
    "\n",
    "# 修正：入力データの次元を調整\n",
    "dummy_time_series = torch.randn(1, sequence_length, input_size)  # [バッチサイズ, シーケンス長, 特徴量数]\n",
    "\n",
    "# モデルを再度実行して潜在ベクトルを取得\n",
    "latent_vector = model(dummy_time_series)\n",
    "latent_vector.shape  # 潜在ベクトルの形状を確認\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macaroni/.conda/envs/torch201_py39/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "# Transformerエンコーダモデルの定義\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, nhead, num_encoder_layers, dim_feedforward):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.linear_in = nn.Linear(input_size, hidden_size)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=nhead, dim_feedforward=dim_feedforward)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_encoder_layers)\n",
    "        self.linear_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.linear_in(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.linear_out(output[-1])  # 最後のタイムステップの出力のみを使用\n",
    "        return output\n",
    "\n",
    "# モデルのパラメータを設定\n",
    "input_size = 10  # 時系列データの特徴量の数\n",
    "hidden_size = 512  # Transformer内部の隠れ状態のサイズ\n",
    "output_size = 128  # 出力する潜在変数の次元数\n",
    "nhead = 8  # マルチヘッドアテンションのヘッド数\n",
    "num_encoder_layers = 3  # エンコーダレイヤーの数\n",
    "dim_feedforward = 2048  # フィードフォワードネットワークの次元\n",
    "\n",
    "# モデルのインスタンス化\n",
    "transformer_model = TransformerModel(input_size, hidden_size, output_size, nhead, num_encoder_layers, dim_feedforward)\n",
    "\n",
    "# ダミーの時系列データを生成（長さは15から20のランダム）\n",
    "sequence_length = random.randint(15, 20)\n",
    "dummy_time_series = torch.randn(sequence_length, 1, input_size)\n",
    "\n",
    "# Transformerモデルに入力\n",
    "# バッチサイズが1のため、[シーケンス長, バッチサイズ, 特徴量数]に変形\n",
    "dummy_time_series = dummy_time_series.permute(1, 0, 2)\n",
    "latent_vector = transformer_model(dummy_time_series)\n",
    "latent_vector.shape  # 潜在ベクトルの形状を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "LSTM: Expected input to be 2D or 3D, got 4D instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprice\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlstm\u001b[39;00m \u001b[39mimport\u001b[39;00m LSTMModel\n\u001b[1;32m      3\u001b[0m \u001b[39m# モデルのパラメータを設定\u001b[39;00m\n\u001b[1;32m      4\u001b[0m input_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# 時系列データの特徴量の数（この場合は1）\u001b[39;00m\n",
      "File \u001b[0;32m~/World_mode_G30/ml/price/lstm.py:34\u001b[0m\n\u001b[1;32m     31\u001b[0m dummy_time_series \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, sequence_length, input_size)  \u001b[39m# [バッチサイズ, シーケンス長, 特徴量数]\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# 潜在ベクトルを取得\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m latent_vector \u001b[39m=\u001b[39m model(dummy_time_series\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m))  \u001b[39m# バッチ次元を追加\u001b[39;00m\n\u001b[1;32m     35\u001b[0m latent_vector\u001b[39m.\u001b[39mshape  \u001b[39m# 潜在ベクトルの形状を確認\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m# 修正：入力データの次元を調整\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch201_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/torch201_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/World_mode_G30/ml/price/lstm.py:14\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     13\u001b[0m     \u001b[39m# LSTMを通して、最後の隠れ状態を取得\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     _, (hidden, _) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[1;32m     15\u001b[0m     \u001b[39m# 隠れ状態を全結合層に通す\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(hidden[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/torch201_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/torch201_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch201_py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py:845\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m--> 845\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLSTM: Expected input to be 2D or 3D, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39mD instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    846\u001b[0m     is_batched \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m    847\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: LSTM: Expected input to be 2D or 3D, got 4D instead"
     ]
    }
   ],
   "source": [
    "from ml.price.lstm import LSTMModel\n",
    "\n",
    "# モデルのパラメータを設定\n",
    "input_size = 1  # 時系列データの特徴量の数（この場合は1）\n",
    "hidden_size = 50  # LSTMの隠れ状態のサイズ\n",
    "output_size = 128  # 出力する潜在変数の次元数\n",
    "\n",
    "# モデルのインスタンス化\n",
    "model = LSTMModel(input_size, hidden_size, output_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch201_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
